[OSEv3:children]
masters
etcd
nodes
lb

[OSEv3:vars]
# General Cluster Variables
## Usuario de ansible
ansible_ssh_user=ansible

## Permitimos que los comandos se ejecuten con 'sudo'
ansible_become=true

## Sincronizamos la hora
openshift_clock_enabled=true

## Nivel de debug
debug_level=4

## Tipo de Clúster a desplegar. Para OKD usar la palabra "origin" y para Openshift Enterprise usar "openshift-enterprise"
openshift_deployment_type=origin

## Versión a instalar.
openshift_release=v3.11

## Habilitamos el audit
openshift_master_audit_config={"enabled": true, "auditFilePath": "/var/lib/origin/audit-ocp.log", "maximumFileRetentionDays": 14, "maximumFileSizeMegabytes": 500, "maximumRetainedFiles": 5}

## Hostname asociado al cluster
openshift_master_cluster_hostname=console.videoconferenciaclaro.com

## Hostname publico, por el que se dara a conocer el cluster
openshift_master_cluster_public_hostname=console.videoconferenciaclaro.com

## Habilita la HA de OKD
openshift_master_cluster_method=native

## Se habilita para permitir reinicios en los master
openshift_rolling_restart_mode=system

## ***Permitimos que todos se puedan autenticar (https://docs.okd.io/3.11/install_config/configuring_authentication.html#AllowAllPasswordIdentityProvider)
openshift_master_identity_providers=[{'name': 'htpasswd_auth','login': 'true', 'challenge': 'true','kind': 'HTPasswdPasswordIdentityProvider',}]
# amxga/abcd1234
openshift_master_htpasswd_users={'amxga': 'amxga:$apr1$tK3xlhz9$TnPbB8NliWxfpKS5raAxX1'}

## Tiempo de expiracion de certificados autogenerados (los coloque a 10 años)
openshift_hosted_registry_cert_expire_days=3650
openshift_ca_cert_expire_days=3650
openshift_node_cert_expire_days=3650
openshift_master_cert_expire_days=3650
etcd_ca_default_days=3650

## Deja de actualizar el cluster (me imagino que es el nodo) una vez que el certificado tenga un tiempo de expiracion menor al indicado
openshift_certificate_expiry_warning_days=180

## Indicamos que se use firewalld 
os_firewall_use_firewalld=true

## Aqui se indica la etiqueta de los servidores en donde deberan desplegarse los router (Deberian ser los bodos de Infra)
openshift_router_selector='node-role.kubernetes.io/infra=true'

## Aqui se indica la etiqueta de los servidores en donde deberán desplegarse el registry interno (Deberian ser los nodos de Infra)
openshift_registry_selector='node-role.kubernetes.io/infra=true'

## Configuracion para permitir el auto-escalado en ambientes de AWS (En nuestro caso no aplica, por eso la ponemos en false)
openshift_master_bootstrap_auto_approve=false

## Aqui se indica donde se hara el despliegue de algunos servicios de Ansible, faltaria investigar para que son esos servicios
ansible_service_broker_node_selector={"node-role.kubernetes.io/infra":"true"}

## Su funcion es la misma que el de la variable ansible_service_broker_node_selector
template_service_broker_selector={"node-role.kubernetes.io/infra":"true"}

## Aqui se indica en que servidores se podra realizar el despliegue de los pods, son todos aquellos computables (App)
osm_default_node_selector='node-role.kubernetes.io/compute=true'

## Indicamos el registry de confianza, si la variable openshift_deployment_type tiene el valor de openshift-enterprise el registry de confianza es registry.redhat.io
openshift_docker_ent_reg='docker.io'

## Tag de las imagenes utilizadas durante el despliegue del cluster
openshift_image_tag=v3.11.0

## Wilcard para exponer las aplicaciones desplegadas en OKD
openshift_master_default_subdomain=apps.videoconferenciaclaro.com

## Aqui indicamos el tipo de red que se desplegara para la conexion entre los pods
os_sdn_network_plugin_name=redhat/openshift-ovs-networkpolicy

## Con esto indicamos que sea flannel el encargado de crear la red que comunicara a los pods y a los services entre si
openshift_use_flannel=false

## Indicamos que se use el plugin por defecto para la creacion de la red que comunicara a los pods y a los services entre si
openshift_use_openshift_sdn=true

## Es para crear una etiqueta especial que permitira agrupar los hosts (No necearia)
openshift_node_groups=[{'name': 'node-config-master', 'labels': ['node-role.kubernetes.io/master=true']}, {'name': 'node-config-infra', 'labels': ['node-role.kubernetes.io/infra=true']}, {'name': 'node-config-compute', 'labels': ['node-role.kubernetes.io/compute=true']}, {'name': 'node-config-log', 'labels': ['node-role.kubernetes.io/log=true']}]

## Puerto por donde se expondra la Api
openshift_master_api_port=8443

## Puerto por donde se expondra la consola web, debe tener el mismo valor que openshift_master_api_port
openshift_master_console_port=8443

## Este check sirve para vigilar que los nodos ya tienen las imágenes que se necesita. Te recomiendo quitarlo o de lo contrario deberás hacer muchos docker pulls en todos los nodos hasta tener TODAS Y CADA UNA de las imágenes necesarias.
openshift_disable_check=docker_image_availability,memory_availability

## Habilitamos las metricas de Hawkular
openshift_metrics_install_metrics=true
openshift_metrics_hawkular_nodeselector={"node-role.kubernetes.io/log": "true"}

## Aprovsionamiento dinamico de los pvc para las metricas
openshift_metrics_cassandra_nodeselector={"node-role.kubernetes.io/log": "true"}
openshift_metrics_heapster_nodeselector={"node-role.kubernetes.io/log": "true"}

## Deshabilitamos el aprovsionamiento dinamico de los pvc (este lo provee Ceph)
openshift_master_dynamic_provisioning_enabled=false

## Habilitamos el logging de OKD
openshift_logging_install_logging=true

## Indicamos en que nodos se hara el almacenamiento de los logs
openshift_logging_es_nodeselector={"node-role.kubernetes.io/log": "true"}
openshift_logging_kibana_nodeselector={"node-role.kubernetes.io/log": "true"} 
openshift_logging_curator_nodeselector={"node-role.kubernetes.io/log": "true"}
openshift_logging_elasticsearch_replace_configmap=true
openshift_logging_es_memory_limit=4G
openshift_logging_elasticsearch_memory_limit=4G

## Instalamos la consola web de OKD
openshift_web_console_install=true

## Url de la consola web
openshift_console_hostname=console.videoconferenciaclaro.com

ansible_service_broker_install=false
template_service_broker_install=false
openshift_enable_olm=true

[okd:vars]
okd_backup_directory=/opt/backup-okd

[all]
jvpo5mast01-1.iris.io
jvpo5mast02-1.iris.io
jvpo5mast03-1.iris.io
jvpo5infr01-1.iris.io
jvpo5infr02-1.iris.io
jvpo5infr03-1.iris.io
jvpoapp01-1.iris.io
jvpoapp02-1.iris.io
jvpoapp03-1.iris.io
jvpoapp04-1.iris.io
jvpoapp05-1.iris.io
jvpo4log01-1.iris.io
jvpo4log02-1.iris.io
jvpo4log03-1.iris.io
jvpb1lb01-1.iris.io
jvpb1lb02-1.iris.io

[okd]
jvpo5mast01-1.iris.io
jvpo5mast02-1.iris.io
jvpo5mast03-1.iris.io
jvpo5infr01-1.iris.io
jvpo5infr02-1.iris.io
jvpo5infr03-1.iris.io
jvpoapp01-1.iris.io
jvpoapp02-1.iris.io
jvpoapp03-1.iris.io
jvpoapp04-1.iris.io
jvpoapp05-1.iris.io
jvpo4log01-1.iris.io
jvpo4log02-1.iris.io
jvpo4log03-1.iris.io
jvpb1lb01-1.iris.io
jvpb1lb02-1.iris.io

[etcd]
jvpo5mast01-1.iris.io
jvpo5mast02-1.iris.io
jvpo5mast03-1.iris.io

[masters]
jvpo5mast01-1.iris.io
jvpo5mast02-1.iris.io
jvpo5mast03-1.iris.io

[nodes]
jvpo5mast01-1.iris.io openshift_node_group_name='node-config-master'
jvpo5mast02-1.iris.io openshift_node_group_name='node-config-master'
jvpo5mast03-1.iris.io openshift_node_group_name='node-config-master'
jvpo5infr01-1.iris.io openshift_node_group_name='node-config-infra'
jvpo5infr02-1.iris.io openshift_node_group_name='node-config-infra'
jvpo5infr03-1.iris.io openshift_node_group_name='node-config-infra'
jvpoapp01-1.iris.io openshift_node_group_name='node-config-compute'
jvpoapp02-1.iris.io openshift_node_group_name='node-config-compute'
jvpoapp03-1.iris.io openshift_node_group_name='node-config-compute'
jvpoapp04-1.iris.io openshift_node_group_name='node-config-compute'
jvpoapp05-1.iris.io openshift_node_group_name='node-config-compute'
jvpo4log01-1.iris.io openshift_node_group_name='node-config-log'
jvpo4log02-1.iris.io openshift_node_group_name='node-config-log'
jvpo4log03-1.iris.io openshift_node_group_name='node-config-log'

[app]
jvpoapp01-1.iris.io
jvpoapp02-1.iris.io
jvpoapp03-1.iris.io
jvpoapp04-1.iris.io
jvpoapp05-1.iris.io

[lb]
jvpb1lb01-1.iris.io
jvpb1lb02-1.iris.io